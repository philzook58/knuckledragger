"""
The kernel hold core proof datatypes and core inference rules. By and large, all proofs must flow through this module.
"""

import kdrag as kd
import kdrag.smt as smt
from dataclasses import dataclass
from typing import Any, Iterable, Sequence
from . import config


class Judgement:
    """
    Judgements should be constructed by smart constructors.
    Having an object of supertype judgement represents having shown some kind of truth.
    Judgements are the things that go above and below inference lines in a proof system.
    Don't worry about it. It is just nice to have a name for the concept.

    See:
    - https://en.wikipedia.org/wiki/Judgment_(mathematical_logic)
    - https://mathoverflow.net/questions/254518/what-exactly-is-a-judgement
    - https://ncatlab.org/nlab/show/judgment
    """


@dataclass(frozen=True)
class Proof(Judgement):
    """
    It is unlikely that users should be accessing the `Proof` constructor directly.
    This is not ironclad. If you really want the Proof constructor, I can't stop you.
    """

    thm: smt.BoolRef
    reason: list[Any]
    admit: bool = False

    def __post_init__(self):
        if self.admit and not config.admit_enabled:
            raise ValueError(
                self.thm, "was called with admit=True but config.admit_enabled=False"
            )

    def __hash__(self) -> int:
        return hash(self.thm)

    def _repr_html_(self):
        return "&#x22A8;" + repr(self.thm)

    def __repr__(self):
        return "|= " + repr(self.thm)

    def forall(self, fresh_vars: list[smt.ExprRef]) -> "Proof":
        """
        Generalize a proof involved schematic variables generated by FreshVar

        >>> x = FreshVar("x", smt.IntSort())
        >>> prove(x + 1 > x).forall([x])
        |= ForAll(x!..., x!... + 1 > x!...)
        """
        return generalize(fresh_vars, self)

    def __call__(self, *args: "smt.ExprRef | Proof"):
        """

        >>> x,y = smt.Ints("x y")
        >>> p = prove(smt.ForAll([y], smt.ForAll([x], x >= x - 1)))
        >>> p(x)
        |= ForAll(x, x >= x - 1)
        >>> p(x, 7)
        |= 7 >= 7 - 1

        >>> a,b,c = smt.Bools("a b c")
        >>> ab = prove(smt.Implies(a,smt.Implies(a, a)))
        >>> a = axiom(a)
        >>> ab(a)
        |= Implies(a, a)
        >>> ab(a,a)
        |= a
        """
        # Note: Not trusted code. Trusted code is in `instan` and `modus`
        acc = self
        n = 0
        while n < len(args):
            if isinstance(self.thm, smt.QuantifierRef) and self.thm.is_forall():
                i = self.thm.num_vars()
                subargs = [
                    a if isinstance(a, smt.ExprRef) else smt._py2expr(a)
                    for a in args[n : n + i]
                ]
                acc = instan(subargs, acc)  # type: ignore
                n += i
            elif smt.is_implies(self.thm):
                x = args[n]
                n += 1
                assert isinstance(x, kd.Proof), "Can only apply implication to kd.Proof"
                acc = modus(acc, x)
            else:
                raise TypeError(
                    "Proofs can only be called with a single argument or a list of arguments for forall quantifiers. "
                    "Use instan for forall quantifiers or modus for implications."
                )
        return acc


def is_proof(p: Proof) -> bool:
    return isinstance(p, Proof)


class LemmaError(Exception):
    pass


def prove(
    thm: smt.BoolRef,
    by: Proof | Iterable[Proof] = [],
    admit=False,
    timeout=1000,
    dump=False,
    solver=None,
) -> Proof:
    """Prove a theorem using a list of previously proved lemmas.

    In essence `prove(Implies(by, thm))`.

    :param thm: The theorem to prove.
    Args:
        thm (smt.BoolRef): The theorem to prove.
        by (list[Proof]): A list of previously proved lemmas.
        admit     (bool): If True, admit the theorem without proof.

    Returns:
        Proof: A proof object of thm

    >>> prove(smt.BoolVal(True))
    |= True
    >>> prove(smt.RealVal(1) >= smt.RealVal(0))
    |= 1 >= 0
    """
    if isinstance(by, Proof):
        by = [by]
    if admit:
        print("Admitting lemma {}".format(thm))
        return Proof(thm, list(by), admit=True)
    else:
        if solver is None:
            s = config.solver()  # type: ignore
        else:
            s = solver()
        s.set("timeout", timeout)
        for p in by:
            if not isinstance(p, Proof):
                raise LemmaError("In by reasons:", p, "is not a Proof object")
            s.add(p.thm)
        s.add(smt.Not(thm))
        if dump:
            print(s.sexpr())
        res = s.check()
        if res != smt.unsat:
            if res == smt.sat:
                raise LemmaError(thm, "Countermodel", s.model())
            raise LemmaError("prove", thm, res)
        else:
            return Proof(thm, list(by), False)


def axiom(thm: smt.BoolRef, by=["axiom"]) -> Proof:
    """Assert an axiom.

    Axioms are necessary and useful. But you must use great care.

    Args:
        thm: The axiom to assert.
        by: A python object explaining why the axiom should exist. Often a string explaining the axiom.
    """
    return Proof(thm, by)


@dataclass(frozen=True)
class Defn(Judgement):
    """
    A record storing definition. It is useful to record definitions as special axioms because we often must unfold them.
    """

    name: str
    decl: smt.FuncDeclRef
    args: list[smt.ExprRef]
    body: smt.ExprRef
    ax: Proof
    _subst_fun_body: (
        smt.ExprRef
    )  # Body with Vars for args. Used for unfolding by z3.substitute_funs

    def __call__(self, *args) -> smt.ExprRef:
        return self.decl(*args)


_datatypes = {}
defns: dict[smt.FuncDeclRef, Defn] = {}
"""
defn holds definitional axioms for function symbols.
"""
smt.FuncDeclRef.defn = property(lambda self: defns[self].ax)
smt.ExprRef.defn = property(lambda self: defns[self.decl()].ax)


def is_defined(x: smt.ExprRef) -> bool:
    """
    Determined if expression head is in definitions.
    """
    return smt.is_app(x) and x.decl() in defns


def fresh_const(q: smt.QuantifierRef, prefixes=None) -> list[smt.ExprRef]:
    """Generate fresh constants of same sort as quantifier."""
    # .split("!") is to remove ugly multiple freshness from names
    if prefixes is None:
        return [
            smt.FreshConst(q.var_sort(i), prefix=q.var_name(i).split("!")[0])
            for i in range(q.num_vars())
        ]
    else:
        prefixes = prefixes.split()
        assert len(prefixes) == q.num_vars()
        return [
            smt.FreshConst(q.var_sort(i), prefix=prefixes[i])
            for i in range(q.num_vars())
        ]


def define(
    name: str, args: list[smt.ExprRef], body: smt.ExprRef, lift_lambda=False
) -> smt.FuncDeclRef:
    """
    Define a non recursive definition. Useful for shorthand and abstraction. Does not currently defend against ill formed definitions.
    TODO: Check for bad circularity, record dependencies

    Args:
        name: The name of the term to define.
        args: The arguments of the term.
        defn: The definition of the term.

    Returns:
        tuple[smt.FuncDeclRef, Proof]: A tuple of the defined term and the proof of the definition.
    """
    sorts = [arg.sort() for arg in args] + [body.sort()]
    f = smt.Function(name, *sorts)
    # TODO: Check body only contain fresh_vars in args
    if len(args) == 0:
        def_ax = axiom(smt.Eq(f(), body), by="definition")
    else:
        def_ax = axiom(
            smt.RawForAll(args, smt.Eq(f(*args), body), patterns=[f(*args)]),
            by="definition",
        )
    defn = Defn(
        name=name,
        decl=f,
        args=args,
        body=body,
        ax=def_ax,
        _subst_fun_body=smt.substitute(
            body, *[(a, smt.Var(n, a.sort())) for n, a in enumerate(args)]
        ),
    )
    if f not in defns or defns[f].ax.thm.eq(def_ax.thm):
        defns[f] = defn
    else:
        print("WARNING: Redefining function", f, "from", defns[f].ax, "to", def_ax.thm)
        defns[f] = defn
    if len(args) == 0:
        return f()  # Convenience
    else:
        return f


def define_fix(name: str, args: list[smt.ExprRef], retsort, fix_lam) -> smt.FuncDeclRef:
    """
    Define a recursive definition.
    """
    sorts = [arg.sort() for arg in args]
    sorts.append(retsort)
    f = smt.Function(name, *sorts)

    # wrapper to record calls
    calls = set()

    def record_f(*args):
        calls.add(args)
        return f(*args)

    defn = define(name, args, fix_lam(record_f))
    # TODO: check for well foundedness/termination, custom induction principle.
    return defn


def unfold(
    e: smt.ExprRef, decls: Sequence[smt.FuncDeclRef]
) -> tuple[smt.ExprRef, Proof]:
    """
    Unfold function definitions in an expression.

    >>> x,y = smt.Ints("x y")
    >>> f = define("f", [x,y], x + 2*y)
    >>> g = define("g", [x,y], f(x,y) + 1)
    >>> unfold(f(42,13) + g(7,8), [f])
    (42 + 2*13 + g(7, 8), |= f(42, 13) + g(7, 8) == 42 + 2*13 + g(7, 8))
    >>> unfold(f(42,13) + g(7,8), [f,g])
    (42 + 2*13 + f(7, 8) + 1, |= f(42, 13) + g(7, 8) == 42 + 2*13 + f(7, 8) + 1)
    """
    assert all(isinstance(d, smt.FuncDeclRef) and d in defns for d in decls), (
        "All decls must be defined functions",
    )
    t = smt.substitute_funs(e, *[(f, defns[f]._subst_fun_body) for f in decls])
    return t, kd.axiom(smt.Eq(e, t), by=["unfold", decls])


def subst(t: smt.ExprRef, eqs: Sequence[Proof]) -> tuple[smt.ExprRef, Proof]:
    """
    Substitute using equality proofs

    >>> x, y = smt.Ints("x y")
    >>> eq = kd.prove(x == ((x + 1) - 1))
    >>> subst(x + 3, [eq])
    (x + 1 - 1 + 3, |= x + 3 == x + 1 - 1 + 3)
    """
    assert all(isinstance(eq, kd.Proof) and smt.is_eq(eq.thm) for eq in eqs)
    subst = [(eq.thm.arg(0), eq.thm.arg(1)) for eq in eqs]
    t1 = smt.substitute(t, *subst)
    return t1, kd.axiom(t == t1, ["subst", t, eqs])


def instan(ts: Sequence[smt.ExprRef], pf: Proof) -> Proof:
    """
    Instantiate a universally quantified formula.
    This is forall elimination
    """
    # Note: modus + specialize easily derive this rule, but it is nice to have it directly.
    assert (
        is_proof(pf)
        and isinstance(pf.thm, smt.QuantifierRef)
        and pf.thm.is_forall()
        and len(ts) == pf.thm.num_vars()
    )

    return axiom(smt.substitute_vars(pf.thm.body(), *reversed(ts)), [pf])


def specialize(ts: Sequence[smt.ExprRef], thm: smt.BoolRef) -> Proof:
    """
    Instantiate a universally quantified formula
    `forall xs, P(xs) -> P(ts)`
    This is forall elimination
    """
    assert (
        isinstance(thm, smt.QuantifierRef)
        and thm.is_forall()
        and len(ts) == thm.num_vars()
    )

    return axiom(
        smt.Implies(thm, smt.substitute_vars(thm.body(), *reversed(ts))),
        ["forall_elim"],
    )


def forget(ts: Sequence[smt.ExprRef], thm: smt.QuantifierRef) -> Proof:
    """
    "Forget" a term using existentials. This is existential introduction.
    `P(ts) -> exists xs, P(xs)`
    `thm` is an existential formula, and `ts` are terms to substitute those variables with.
    forget easily follows.
    https://en.wikipedia.org/wiki/Existential_generalization
    """
    assert smt.is_quantifier(thm) and thm.is_exists() and len(ts) == thm.num_vars()
    return axiom(
        smt.Implies(smt.substitute_vars(thm.body(), *reversed(ts)), thm),
        ["exists_intro"],
    )


def obtain(thm: smt.QuantifierRef) -> tuple[list[smt.ExprRef], Proof]:
    """
    Skolemize an existential quantifier.
    `exists xs, P(xs) -> P(cs)` for fresh cs
    https://en.wikipedia.org/wiki/Existential_instantiation

    >>> x = smt.Int("x")
    >>> obtain(smt.Exists([x], x >= 0))
    ([x!...], |=  Implies(Exists(x, x >= 0), x!... >= 0))
    >>> y = FreshVar("y", smt.IntSort())
    >>> obtain(smt.Exists([x], x >= y))
    ([f!...(y!...)], |=  Implies(Exists(x, x >= y!...), f!...(y!...) >= y!...))

    """
    # TODO: Hmm. Maybe we don't need to have a Proof? Lessen this to thm.
    assert smt.is_quantifier(thm) and thm.is_exists()

    free_vars = set()
    todo = [thm.body()]
    # collect free variables in body
    while todo:
        t = todo.pop()
        if smt.is_const(t):
            if t.get_id() in _overapproximate_fresh_ids:
                free_vars.add(t)
        elif smt.is_app(t):
            todo.extend(t.children())
        elif isinstance(t, smt.QuantifierRef):
            todo.append(t.body())
        elif smt.is_var(t):
            continue
        else:
            raise Exception("Unexpected term in consts", t)
    if len(free_vars) == 0:
        skolems = fresh_const(thm)
    else:
        free_vars = list(free_vars)
        sorts = [v.sort() for v in free_vars]
        skolems = [
            smt.FreshFunction(*sorts, thm.var_sort(i))(*free_vars)
            for i in range(thm.num_vars())
        ]
    return skolems, axiom(
        smt.Implies(thm, smt.substitute_vars(thm.body(), *reversed(skolems))),
        ["obtain"],
    )


def herb(thm: smt.QuantifierRef, prefixes=None) -> tuple[list[smt.ExprRef], Proof]:
    """
    Herbrandize a theorem.
    It is sufficient to prove a theorem for fresh consts to prove a universal.
    Note: Perhaps lambdaized form is better? Return vars and lamda that could receive `|= P[vars]`

    >>> x = smt.Int("x")
    >>> herb(smt.ForAll([x], x >= x))
    ([x!...], |=  Implies(x!... >= x!..., ForAll(x, x >= x)))
    """
    assert smt.is_quantifier(thm) and thm.is_forall()
    herbs = fresh_const(
        thm, prefixes=prefixes
    )  # We could mark these as schema variables? Useful?
    return herbs, axiom(
        smt.Implies(smt.substitute_vars(thm.body(), *reversed(herbs)), thm),
        ["herbrand"],
    )


def ext(domain: Sequence[smt.SortRef], range_: smt.SortRef) -> Proof:
    """
    >>> ext([smt.IntSort()], smt.IntSort())
    |= ForAll([f, g], (f == g) == (ForAll(x0, f[x0] == g[x0])))
    >>> ext([smt.IntSort(), smt.RealSort()], smt.IntSort())
    |= ForAll([f, g],
           (f == g) ==
           (ForAll([x0, x1],
                   Select(f, x0, x1) == Select(g, x0, x1))))
    """
    assert len(domain) >= 1
    T = smt.ArraySort(*domain, range_)
    f, g = smt.Consts("f g", T)
    xs = [smt.Const(f"x{n}", sort) for n, sort in enumerate(domain)]
    return kd.axiom(
        smt.RawForAll([f, g], smt.Eq((f == g), smt.RawForAll(xs, f[*xs] == g[*xs]))),
        ["ext"],
    )


def modus(ab: Proof, a: Proof) -> Proof:
    """
    Modus ponens for implies and equality.

    >>> a,b = smt.Bools("a b")
    >>> ab = axiom(smt.Implies(a, b))
    >>> a = axiom(a)
    >>> modus(ab, a)
    |= b
    >>> ab1 = axiom(smt.Eq(a.thm, b))
    >>> modus(ab1, a)
    |= b
    """
    assert isinstance(ab, Proof) and isinstance(a, Proof)
    assert smt.is_implies(ab.thm) or smt.is_eq(ab.thm)
    assert ab.thm.arg(0).eq(a.thm)
    return axiom(ab.thm.arg(1), ["modus", ab, a])


def andI(pfs: Sequence[Proof]) -> Proof:
    """
    Prove an and from two kd.Proofs of its conjuncts.

    >>> a, b = smt.Bools("a b")
    >>> pa = kd.axiom(smt.Implies(True, a))
    >>> pb = kd.axiom(smt.Implies(True, b))
    >>> andI([pa, pb, pb])
    |= Implies(True, And(a, b, b))
    """
    assert all(isinstance(pf, Proof) for pf in pfs)
    ctx = pfs[0].thm.arg(0)
    assert all(smt.is_implies(pf.thm) and pf.thm.arg(0).eq(ctx) for pf in pfs)
    return kd.axiom(
        smt.Implies(ctx, smt.And([pf.thm.arg(1) for pf in pfs])), ["andI", pfs]
    )


def compose(ab: Proof, bc: Proof) -> Proof:
    """
    Compose two implications. Useful for chaining implications.

    >>> a,b,c = smt.Bools("a b c")
    >>> ab = axiom(smt.Implies(a, b))
    >>> bc = axiom(smt.Implies(b, c))
    >>> compose(ab, bc)
    |= Implies(a, c)
    """
    assert isinstance(ab, Proof) and isinstance(bc, Proof)
    assert smt.is_implies(ab.thm) and smt.is_implies(bc.thm)
    assert ab.thm.arg(1).eq(bc.thm.arg(0))
    return axiom(smt.Implies(ab.thm.arg(0), bc.thm.arg(1)), ["compose", ab, bc])


def induct_inductive(x: smt.DatatypeRef, P: smt.QuantifierRef) -> Proof:
    """Build a basic induction principle for an algebraic datatype"""
    DT = x.sort()
    assert isinstance(DT, smt.DatatypeSortRef)
    """assert (
        isisntance(P,QuantififerRef) and P.is_lambda()
    )  # TODO: Hmm. Actually it should just be arraysort"""
    hyps = []
    for i in range(DT.num_constructors()):
        constructor = DT.constructor(i)
        args = [
            smt.FreshConst(constructor.domain(j), prefix=DT.accessor(i, j).name())
            for j in range(constructor.arity())
        ]
        head = P(constructor(*args))
        body = [P(arg) for arg in args if arg.sort() == DT]
        if len(args) == 0:
            hyps.append(head)
        else:
            hyps.append(kd.QForAll(args, *body, head))
    conc = P(x)
    return axiom(smt.Implies(smt.And(hyps), conc), by="induction_axiom_schema")


def Inductive(name: str) -> smt.Datatype:
    """
    Declare datatypes with auto generated induction principles. Wrapper around z3.Datatype

    >>> Nat = Inductive("Nat")
    >>> Nat.declare("zero")
    >>> Nat.declare("succ", ("pred", Nat))
    >>> Nat = Nat.create()
    >>> Nat.succ(Nat.zero)
    succ(zero)
    """
    counter = 0
    n = name
    while n in _datatypes:
        counter += 1
        n = name + "!" + str(counter)
    name = n
    assert name not in _datatypes
    dt = smt.Datatype(name)
    oldcreate = dt.create

    def create() -> smt.DatatypeSortRef:
        dt = oldcreate()
        # Sanity check no duplicate names. Causes confusion.
        names = set()
        for i in range(dt.num_constructors()):
            cons = dt.constructor(i)
            n = cons.name()
            if n in names:
                raise Exception("Duplicate constructor name", n)
            names.add(n)
            for j in range(cons.arity()):
                n = dt.accessor(i, j).name()
                if n in names:
                    raise Exception("Duplicate field name", n)
                names.add(n)
        kd.notation.induct.register(dt, induct_inductive)
        _datatypes[name] = dt
        smt.sort_registry[dt.get_id()] = dt
        return dt

    dt.create = create
    return dt


_overapproximate_fresh_ids = set()
"""
This set tracks an overapproximation of the ids of schema variables.
It is an overapproximation because I think it is possible that z3 reuses ids of deleted terms.
This overapproximation is nevertheless useful for finding an overapproximation of free schema variables in a term. for skolemization
"""


@dataclass(frozen=True)
class _FreshVarEvidence(Judgement):
    """
    Do not instantiate this class directly.
    Use `FreshVar`. This class should always be created with a fresh variable.
    Holding this data type is considered evidence analogous to the `Proof` type that the var was generated freshly
    and hence is generic / schematic.

    One can prove theorem using this variable as a constant, but once it comes to generalize, you need to supply the evidence
    That it was originally generated freshly.
    """

    v: smt.ExprRef


def is_fresh_var(v: smt.ExprRef) -> bool:
    """
    Check if a variable is a schema variable.
    Schema variables are generated by FreshVar and have a _FreshVarEvidence attribute.

    >>> is_fresh_var(FreshVar("x", smt.IntSort()))
    True
    """
    if not hasattr(v, "fresh_evidence"):
        return False
    else:
        evidence = getattr(v, "fresh_evidence")
        return isinstance(evidence, _FreshVarEvidence) and evidence.v.eq(v)


def FreshVar(prefix: str, sort: smt.SortRef) -> smt.ExprRef:
    """
    Generate a fresh variable. This is distinguished from FreshConst by the fact that it has freshness evidence.
    This is intended to be used for constants that represent arbitrary terms (implicitly universally quantified).
    For example, axioms like `c_fresh = t` should never be asserted about bare FreshVars as they imply a probably inconsistent axiom,
    whereas asserting such an axiom about FreshConst is ok, effectively defining a new rigid constant.


    >>> FreshVar("x", smt.IntSort()).fresh_evidence
    _FreshVarEvidence(v=x!...)
    """
    v = smt.FreshConst(sort, prefix=prefix)
    _overapproximate_fresh_ids.add(v.get_id())
    v.fresh_evidence = _FreshVarEvidence(
        v
    )  # Is cyclic reference a garbage collection problem?
    return v


def generalize(vs: list[smt.ExprRef], pf: Proof) -> Proof:
    """
    Generalize a theorem with respect to a list of schema variables.
    This introduces a universal quantifier for schema variables.

    >>> x = FreshVar("x", smt.IntSort())
    >>> y = FreshVar("y", smt.IntSort())
    >>> generalize([x, y], prove(x == x))
    |= ForAll([x!..., y!...], x!... == x!...)
    """
    assert all(is_fresh_var(v) for v in vs)
    assert isinstance(pf, Proof)
    return axiom(smt.RawForAll(vs, pf.thm), by=["generalize", vs, pf])


def rename_vars2(
    pf: Proof, vs: list[smt.ExprRef], patterns=[], no_patterns=[]
) -> Proof:
    """
    Rename bound variables and also attach triggers

    >>> x,y = smt.Ints("x y")
    >>> f = smt.Function("f", smt.IntSort(), smt.IntSort())
    >>> rename_vars2(kd.prove(smt.ForAll([x, y], x + 1 > x)), [y,x], patterns=[x+y])
    |= ForAll([y, x], y + 1 > y)
    >>> rename_vars2(kd.prove(smt.Exists([x], x + 1 > y)), [y])
    Traceback (most recent call last):
        ...
    ValueError: ('Cannot rename vars to ones that already occur in term', [y], Exists(x, x + 1 > y))
    """
    assert isinstance(pf, Proof)
    thm = pf.thm
    assert isinstance(thm, smt.QuantifierRef)
    t_body = thm.body()
    body = smt.substitute_vars(t_body, *reversed(vs))
    if thm.is_forall():
        t2 = smt.ForAll(vs, body, patterns=patterns, no_patterns=no_patterns)
    elif thm.is_exists():
        t2 = smt.Exists(vs, body, patterns=patterns, no_patterns=no_patterns)
    else:
        raise Exception("Unknown quantifier type", thm)
    if not t2.body().eq(t_body):
        raise ValueError(
            "Cannot rename vars to ones that already occur in term", vs, thm
        )
    return axiom(t2, by=["rename", pf, vs])
